{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qgldp_3-Dn0c"
      },
      "source": [
        "# Dataloader Arguments & Test/Train Dataloaders\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "drokW8wWODKq"
      },
      "source": [
        "# Let's Train and test our model\n",
        "\n",
        "This time let's add a scheduler for out LR."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wjO3RK9UEnvF"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "dropout_value = 0.05\n",
        "\n",
        "class DepthwiseSeparableConv(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, padding=1):\n",
        "        super(DepthwiseSeparableConv, self).__init__()\n",
        "        self.depthwise = nn.Conv2d(\n",
        "            in_channels, in_channels, kernel_size, stride, padding, groups=in_channels\n",
        "        )\n",
        "        self.pointwise = nn.Sequential(nn.Conv2d(in_channels, out_channels, kernel_size=1),\n",
        "        nn.ReLU(),\n",
        "        nn.BatchNorm2d(out_channels),\n",
        "        nn.Dropout(dropout_value)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.depthwise(x)\n",
        "        x = self.pointwise(x)\n",
        "        return x\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        # Input Block\n",
        "        self.convblock1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=3, out_channels=16, kernel_size=(3, 3), padding=1, bias=False),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.Dropout(dropout_value)\n",
        "        ) # output_size = 32 , receptive_field = 3\n",
        "\n",
        "        self.convblock2 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=(3, 3), padding=1, bias=False),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.Dropout(dropout_value)\n",
        "        ) # output_size = 32 , receptive_field = 5\n",
        "\n",
        "        self.convblock3 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(3, 3), stride=2, padding=1, bias=False),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.Dropout(dropout_value)\n",
        "        ) # output_size = 16 , receptive_field = 7\n",
        "\n",
        "        self.convblock4 = DepthwiseSeparableConv(in_channels=64, out_channels=128)\n",
        "        # output_size = 16 , receptive_field = 11\n",
        "\n",
        "        #self.convblock4 = nn.Sequential(\n",
        "        #    nn.Conv2d(in_channels=64, out_channels=128, kernel_size=(3, 3), padding=1, bias=False),\n",
        "        #    nn.ReLU(),\n",
        "        #    nn.BatchNorm2d(128),\n",
        "        #    nn.Dropout(dropout_value)\n",
        "        #) # output_size = 16 , receptive_field = 11\n",
        "\n",
        "        # TRANSITION BLOCK 1\n",
        "        self.convblock5 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=128, out_channels=16, kernel_size=(1, 1), padding=0, bias=False),\n",
        "        ) # output_size = 16 , receptive_field = 11\n",
        "\n",
        "        self.convblock6 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=(3, 3), padding=1, bias=False),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.Dropout(dropout_value)\n",
        "        ) # output_size = 16 , receptive_field = 15\n",
        "\n",
        "        self.convblock7 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(3, 3), padding=1, bias=False),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.Dropout(dropout_value)\n",
        "        ) # output_size = 16 , receptive_field = 19\n",
        "\n",
        "        #self.convblock8 = DepthwiseSeparableConv(in_channels=64, out_channels=128)\n",
        "        #output_size = 14 , receptive_field = 31\n",
        "\n",
        "        self.convblock8 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=(3, 3), dilation=2, padding=1, bias=False),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.Dropout(dropout_value)\n",
        "        ) # output_size = 14 , receptive_field = 27\n",
        "\n",
        "         # TRANSITION BLOCK 2\n",
        "        self.convblock9 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=128, out_channels=16, kernel_size=(1, 1), padding=0, bias=False),\n",
        "        ) # output_size = 14 , receptive_field = 27\n",
        "\n",
        "        self.convblock10 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=(3, 3), padding=1, bias=False),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.Dropout(dropout_value)\n",
        "        ) # output_size = 14 , receptive_field = 35\n",
        "\n",
        "        self.convblock11 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(3, 3), stride=2, padding=1, bias=False),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.Dropout(dropout_value)\n",
        "        ) # output_size = 7 , receptive_field = 43\n",
        "\n",
        "        self.convblock12 = DepthwiseSeparableConv(in_channels=64, out_channels=128)\n",
        "        # output_size = 7 , receptive_field = 55\n",
        "\n",
        "        # OUTPUT BLOCK\n",
        "        self.gap = nn.Sequential(\n",
        "            nn.AvgPool2d(kernel_size=7)\n",
        "        ) # output_size = 1\n",
        "\n",
        "        self.convblock13 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=128, out_channels=10, kernel_size=(1, 1), padding=0, bias=False),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.convblock1(x)\n",
        "        x = self.convblock2(x)\n",
        "        x = self.convblock3(x)\n",
        "        x = self.convblock4(x)\n",
        "        x = self.convblock5(x)\n",
        "        x = self.convblock6(x)\n",
        "        x = self.convblock7(x)\n",
        "        x = self.convblock8(x)\n",
        "        x = self.convblock9(x)\n",
        "        x = self.convblock10(x)\n",
        "        x = self.convblock11(x)\n",
        "        x = self.convblock12(x)\n",
        "        x = self.gap(x)\n",
        "        x = self.convblock13(x)\n",
        "\n",
        "        x = x.view(-1, 10)\n",
        "        return F.log_softmax(x, dim=-1)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "import cv2\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# CIFAR-10 Mean and Std (calculated over the entire dataset)\n",
        "CIFAR10_MEAN = (0.4914, 0.4822, 0.4465)\n",
        "CIFAR10_STD = (0.2470, 0.2435, 0.2616)\n",
        "\n",
        "# Albumentations Transformations\n",
        "class AlbumentationsTransform:\n",
        "    def __init__(self, mean, std):\n",
        "        self.transform = A.Compose([\n",
        "            A.HorizontalFlip(p=0.5),  # Random horizontal flip\n",
        "            A.ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.1, rotate_limit=15, p=0.5),  # Shift, Scale, Rotate\n",
        "            A.CoarseDropout(max_holes=1, max_height=16, max_width=16, min_holes=1, min_height=16, min_width=16,\n",
        "                            fill_value=(np.array(mean) * 255).tolist(), mask_fill_value=None, p=0.5),  # CoarseDropout\n",
        "            A.Normalize(mean=mean, std=std, max_pixel_value=255.0),  # Normalize\n",
        "            ToTensorV2(),  # Convert to tensor\n",
        "        ])\n",
        "\n",
        "    def __call__(self, img):\n",
        "        # Albumentations expects the image in OpenCV format (HWC, uint8)\n",
        "        image = np.array(img)  # Convert PIL image to numpy array\n",
        "        return self.transform(image=image)[\"image\"]\n",
        "\n",
        "# Apply Albumentations Transformations to CIFAR-10\n",
        "train = datasets.CIFAR10(\n",
        "    root=\"./data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=AlbumentationsTransform(mean=CIFAR10_MEAN, std=CIFAR10_STD)\n",
        ")\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=CIFAR10_MEAN, std=CIFAR10_STD)\n",
        "])\n",
        "\n",
        "test = datasets.CIFAR10(\n",
        "    root=\"./data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=test_transform\n",
        ")\n",
        "\n",
        "SEED = 1\n",
        "\n",
        "# CUDA?\n",
        "cuda = torch.cuda.is_available()\n",
        "print(\"CUDA Available?\", cuda)\n",
        "\n",
        "# For reproducibility\n",
        "torch.manual_seed(SEED)\n",
        "\n",
        "if cuda:\n",
        "    torch.cuda.manual_seed(SEED)\n",
        "\n",
        "# dataloader arguments - something you'll fetch these from cmdprmt\n",
        "dataloader_args = dict(shuffle=True, batch_size=128, num_workers=4, pin_memory=True) if cuda else dict(shuffle=True, batch_size=64)\n",
        "\n",
        "# train dataloader\n",
        "train_loader = torch.utils.data.DataLoader(train, **dataloader_args)\n",
        "\n",
        "# test dataloader\n",
        "test_loader = torch.utils.data.DataLoader(test, **dataloader_args)\n",
        "\n",
        "\n",
        "from torchsummary import summary\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "print(device)\n",
        "model = Net().to(device)\n",
        "summary(model, input_size=(3, 32, 32))\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "train_losses = []\n",
        "test_losses = []\n",
        "train_acc = []\n",
        "test_acc = []\n",
        "\n",
        "def train(model, device, train_loader, optimizer, epoch):\n",
        "  model.train()\n",
        "  pbar = tqdm(train_loader)\n",
        "  correct = 0\n",
        "  processed = 0\n",
        "  for batch_idx, (data, target) in enumerate(pbar):\n",
        "    # get samples\n",
        "    data, target = data.to(device), target.to(device)\n",
        "\n",
        "    # Init\n",
        "    optimizer.zero_grad()\n",
        "    # In PyTorch, we need to set the gradients to zero before starting to do backpropragation because PyTorch accumulates the gradients on subsequent backward passes.\n",
        "    # Because of this, when you start your training loop, ideally you should zero out the gradients so that you do the parameter update correctly.\n",
        "\n",
        "    # Predict\n",
        "    y_pred = model(data)\n",
        "\n",
        "    # Calculate loss\n",
        "    loss = F.nll_loss(y_pred, target)\n",
        "    train_losses.append(loss)\n",
        "\n",
        "    # Backpropagation\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # Update pbar-tqdm\n",
        "\n",
        "    pred = y_pred.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "    correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "    processed += len(data)\n",
        "\n",
        "    pbar.set_description(desc= f'Loss={loss.item()} Batch_id={batch_idx} Accuracy={100*correct/processed:0.2f}')\n",
        "    train_acc.append(100*correct/processed)\n",
        "\n",
        "def test(model, device, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
        "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    test_losses.append(test_loss)\n",
        "\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))\n",
        "\n",
        "    test_acc.append(100. * correct / len(test_loader.dataset))\n",
        "\n",
        "\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "\n",
        "model =  Net().to(device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=1,cooldown=5)\n",
        "\n",
        "\n",
        "EPOCHS = 35\n",
        "for epoch in range(EPOCHS):\n",
        "    print(\"EPOCH:\", epoch)\n",
        "    train(model, device, train_loader, optimizer, epoch)\n",
        "    test(model, device, test_loader)\n",
        "    scheduler.step(test_losses[epoch])\n",
        "    print(f\"Learning Rate = {optimizer.param_groups[0]['lr']}\\n\")\n",
        "    #if (test_acc[epoch] > 99.4):\n",
        "    #  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aoq1J_OoY_Gv",
        "outputId": "91b46867-e1d7-4ecd-8903-8e750d039e2a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "CUDA Available? True\n",
            "cuda\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 16, 32, 32]             432\n",
            "              ReLU-2           [-1, 16, 32, 32]               0\n",
            "       BatchNorm2d-3           [-1, 16, 32, 32]              32\n",
            "           Dropout-4           [-1, 16, 32, 32]               0\n",
            "            Conv2d-5           [-1, 32, 32, 32]           4,608\n",
            "              ReLU-6           [-1, 32, 32, 32]               0\n",
            "       BatchNorm2d-7           [-1, 32, 32, 32]              64\n",
            "           Dropout-8           [-1, 32, 32, 32]               0\n",
            "            Conv2d-9           [-1, 64, 16, 16]          18,432\n",
            "             ReLU-10           [-1, 64, 16, 16]               0\n",
            "      BatchNorm2d-11           [-1, 64, 16, 16]             128\n",
            "          Dropout-12           [-1, 64, 16, 16]               0\n",
            "           Conv2d-13           [-1, 64, 16, 16]             640\n",
            "           Conv2d-14          [-1, 128, 16, 16]           8,320\n",
            "             ReLU-15          [-1, 128, 16, 16]               0\n",
            "      BatchNorm2d-16          [-1, 128, 16, 16]             256\n",
            "          Dropout-17          [-1, 128, 16, 16]               0\n",
            "DepthwiseSeparableConv-18          [-1, 128, 16, 16]               0\n",
            "           Conv2d-19           [-1, 16, 16, 16]           2,048\n",
            "           Conv2d-20           [-1, 32, 16, 16]           4,608\n",
            "             ReLU-21           [-1, 32, 16, 16]               0\n",
            "      BatchNorm2d-22           [-1, 32, 16, 16]              64\n",
            "          Dropout-23           [-1, 32, 16, 16]               0\n",
            "           Conv2d-24           [-1, 64, 16, 16]          18,432\n",
            "             ReLU-25           [-1, 64, 16, 16]               0\n",
            "      BatchNorm2d-26           [-1, 64, 16, 16]             128\n",
            "          Dropout-27           [-1, 64, 16, 16]               0\n",
            "           Conv2d-28          [-1, 128, 14, 14]          73,728\n",
            "             ReLU-29          [-1, 128, 14, 14]               0\n",
            "      BatchNorm2d-30          [-1, 128, 14, 14]             256\n",
            "          Dropout-31          [-1, 128, 14, 14]               0\n",
            "           Conv2d-32           [-1, 16, 14, 14]           2,048\n",
            "           Conv2d-33           [-1, 32, 14, 14]           4,608\n",
            "             ReLU-34           [-1, 32, 14, 14]               0\n",
            "      BatchNorm2d-35           [-1, 32, 14, 14]              64\n",
            "          Dropout-36           [-1, 32, 14, 14]               0\n",
            "           Conv2d-37             [-1, 64, 7, 7]          18,432\n",
            "             ReLU-38             [-1, 64, 7, 7]               0\n",
            "      BatchNorm2d-39             [-1, 64, 7, 7]             128\n",
            "          Dropout-40             [-1, 64, 7, 7]               0\n",
            "           Conv2d-41             [-1, 64, 7, 7]             640\n",
            "           Conv2d-42            [-1, 128, 7, 7]           8,320\n",
            "             ReLU-43            [-1, 128, 7, 7]               0\n",
            "      BatchNorm2d-44            [-1, 128, 7, 7]             256\n",
            "          Dropout-45            [-1, 128, 7, 7]               0\n",
            "DepthwiseSeparableConv-46            [-1, 128, 7, 7]               0\n",
            "        AvgPool2d-47            [-1, 128, 1, 1]               0\n",
            "           Conv2d-48             [-1, 10, 1, 1]           1,280\n",
            "================================================================\n",
            "Total params: 167,952\n",
            "Trainable params: 167,952\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 5.50\n",
            "Params size (MB): 0.64\n",
            "Estimated Total Size (MB): 6.15\n",
            "----------------------------------------------------------------\n",
            "EPOCH: 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=1.7189695835113525 Batch_id=390 Accuracy=38.77: 100%|██████████| 391/391 [00:30<00:00, 12.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 1.4120, Accuracy: 4764/10000 (47.64%)\n",
            "\n",
            "Learning Rate = 0.01\n",
            "\n",
            "EPOCH: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=1.0850272178649902 Batch_id=390 Accuracy=52.15: 100%|██████████| 391/391 [00:30<00:00, 12.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 1.0884, Accuracy: 6092/10000 (60.92%)\n",
            "\n",
            "Learning Rate = 0.01\n",
            "\n",
            "EPOCH: 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=1.075197458267212 Batch_id=390 Accuracy=58.99: 100%|██████████| 391/391 [00:30<00:00, 13.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 1.0592, Accuracy: 6341/10000 (63.41%)\n",
            "\n",
            "Learning Rate = 0.01\n",
            "\n",
            "EPOCH: 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.8908108472824097 Batch_id=390 Accuracy=62.99: 100%|██████████| 391/391 [00:30<00:00, 12.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.8372, Accuracy: 7031/10000 (70.31%)\n",
            "\n",
            "Learning Rate = 0.01\n",
            "\n",
            "EPOCH: 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.9221165776252747 Batch_id=390 Accuracy=65.96: 100%|██████████| 391/391 [00:29<00:00, 13.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.7430, Accuracy: 7388/10000 (73.88%)\n",
            "\n",
            "Learning Rate = 0.01\n",
            "\n",
            "EPOCH: 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.5385757684707642 Batch_id=390 Accuracy=67.72: 100%|██████████| 391/391 [00:30<00:00, 12.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.7203, Accuracy: 7513/10000 (75.13%)\n",
            "\n",
            "Learning Rate = 0.01\n",
            "\n",
            "EPOCH: 6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.7203976511955261 Batch_id=390 Accuracy=69.53: 100%|██████████| 391/391 [00:32<00:00, 11.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.6915, Accuracy: 7614/10000 (76.14%)\n",
            "\n",
            "Learning Rate = 0.01\n",
            "\n",
            "EPOCH: 7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.7643371820449829 Batch_id=390 Accuracy=70.96: 100%|██████████| 391/391 [00:30<00:00, 12.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.6585, Accuracy: 7735/10000 (77.35%)\n",
            "\n",
            "Learning Rate = 0.01\n",
            "\n",
            "EPOCH: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=1.0443222522735596 Batch_id=390 Accuracy=72.17: 100%|██████████| 391/391 [00:29<00:00, 13.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.6442, Accuracy: 7824/10000 (78.24%)\n",
            "\n",
            "Learning Rate = 0.01\n",
            "\n",
            "EPOCH: 9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.8592268228530884 Batch_id=390 Accuracy=72.62: 100%|██████████| 391/391 [00:29<00:00, 13.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.6084, Accuracy: 7913/10000 (79.13%)\n",
            "\n",
            "Learning Rate = 0.01\n",
            "\n",
            "EPOCH: 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.9151142239570618 Batch_id=390 Accuracy=73.62: 100%|██████████| 391/391 [00:29<00:00, 13.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.5724, Accuracy: 8059/10000 (80.59%)\n",
            "\n",
            "Learning Rate = 0.01\n",
            "\n",
            "EPOCH: 11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.7979899048805237 Batch_id=390 Accuracy=74.32: 100%|██████████| 391/391 [00:29<00:00, 13.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.5662, Accuracy: 8073/10000 (80.73%)\n",
            "\n",
            "Learning Rate = 0.01\n",
            "\n",
            "EPOCH: 12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.6217381954193115 Batch_id=390 Accuracy=75.27: 100%|██████████| 391/391 [00:29<00:00, 13.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.5567, Accuracy: 8113/10000 (81.13%)\n",
            "\n",
            "Learning Rate = 0.01\n",
            "\n",
            "EPOCH: 13\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.6652392148971558 Batch_id=390 Accuracy=75.57: 100%|██████████| 391/391 [00:29<00:00, 13.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.5320, Accuracy: 8173/10000 (81.73%)\n",
            "\n",
            "Learning Rate = 0.01\n",
            "\n",
            "EPOCH: 14\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.7526963949203491 Batch_id=390 Accuracy=76.01: 100%|██████████| 391/391 [00:32<00:00, 12.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.5345, Accuracy: 8171/10000 (81.71%)\n",
            "\n",
            "Learning Rate = 0.01\n",
            "\n",
            "EPOCH: 15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.7423626780509949 Batch_id=390 Accuracy=76.80: 100%|██████████| 391/391 [00:30<00:00, 12.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.4937, Accuracy: 8313/10000 (83.13%)\n",
            "\n",
            "Learning Rate = 0.01\n",
            "\n",
            "EPOCH: 16\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.5244418978691101 Batch_id=390 Accuracy=76.96: 100%|██████████| 391/391 [00:30<00:00, 12.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.4980, Accuracy: 8304/10000 (83.04%)\n",
            "\n",
            "Learning Rate = 0.01\n",
            "\n",
            "EPOCH: 17\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.7348312735557556 Batch_id=390 Accuracy=77.51: 100%|██████████| 391/391 [00:29<00:00, 13.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.4905, Accuracy: 8319/10000 (83.19%)\n",
            "\n",
            "Learning Rate = 0.01\n",
            "\n",
            "EPOCH: 18\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.557018518447876 Batch_id=390 Accuracy=77.96: 100%|██████████| 391/391 [00:29<00:00, 13.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.4877, Accuracy: 8332/10000 (83.32%)\n",
            "\n",
            "Learning Rate = 0.01\n",
            "\n",
            "EPOCH: 19\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.705111563205719 Batch_id=390 Accuracy=78.18: 100%|██████████| 391/391 [00:30<00:00, 12.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.4657, Accuracy: 8426/10000 (84.26%)\n",
            "\n",
            "Learning Rate = 0.01\n",
            "\n",
            "EPOCH: 20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.5907760262489319 Batch_id=390 Accuracy=78.29: 100%|██████████| 391/391 [00:29<00:00, 13.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.4532, Accuracy: 8441/10000 (84.41%)\n",
            "\n",
            "Learning Rate = 0.01\n",
            "\n",
            "EPOCH: 21\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.5677151679992676 Batch_id=390 Accuracy=78.70: 100%|██████████| 391/391 [00:29<00:00, 13.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.4544, Accuracy: 8462/10000 (84.62%)\n",
            "\n",
            "Learning Rate = 0.01\n",
            "\n",
            "EPOCH: 22\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.7409203052520752 Batch_id=390 Accuracy=79.15: 100%|██████████| 391/391 [00:31<00:00, 12.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.4561, Accuracy: 8451/10000 (84.51%)\n",
            "\n",
            "Learning Rate = 0.001\n",
            "\n",
            "EPOCH: 23\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.6016901731491089 Batch_id=390 Accuracy=80.74: 100%|██████████| 391/391 [00:30<00:00, 12.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.4074, Accuracy: 8612/10000 (86.12%)\n",
            "\n",
            "Learning Rate = 0.001\n",
            "\n",
            "EPOCH: 24\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.7034579515457153 Batch_id=390 Accuracy=81.82: 100%|██████████| 391/391 [00:31<00:00, 12.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.3974, Accuracy: 8631/10000 (86.31%)\n",
            "\n",
            "Learning Rate = 0.001\n",
            "\n",
            "EPOCH: 25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.36901330947875977 Batch_id=390 Accuracy=81.90: 100%|██████████| 391/391 [00:30<00:00, 12.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.3982, Accuracy: 8648/10000 (86.48%)\n",
            "\n",
            "Learning Rate = 0.001\n",
            "\n",
            "EPOCH: 26\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.4636271595954895 Batch_id=390 Accuracy=82.21: 100%|██████████| 391/391 [00:30<00:00, 12.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.3952, Accuracy: 8658/10000 (86.58%)\n",
            "\n",
            "Learning Rate = 0.001\n",
            "\n",
            "EPOCH: 27\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.4217306971549988 Batch_id=390 Accuracy=82.12: 100%|██████████| 391/391 [00:30<00:00, 12.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.3952, Accuracy: 8652/10000 (86.52%)\n",
            "\n",
            "Learning Rate = 0.001\n",
            "\n",
            "EPOCH: 28\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.485289990901947 Batch_id=390 Accuracy=82.34: 100%|██████████| 391/391 [00:30<00:00, 12.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.3956, Accuracy: 8644/10000 (86.44%)\n",
            "\n",
            "Learning Rate = 0.001\n",
            "\n",
            "EPOCH: 29\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.4194835126399994 Batch_id=390 Accuracy=82.33: 100%|██████████| 391/391 [00:30<00:00, 12.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.3888, Accuracy: 8675/10000 (86.75%)\n",
            "\n",
            "Learning Rate = 0.001\n",
            "\n",
            "EPOCH: 30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.6461837887763977 Batch_id=390 Accuracy=82.29: 100%|██████████| 391/391 [00:31<00:00, 12.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.3889, Accuracy: 8681/10000 (86.81%)\n",
            "\n",
            "Learning Rate = 0.001\n",
            "\n",
            "EPOCH: 31\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.5050350427627563 Batch_id=390 Accuracy=82.45: 100%|██████████| 391/391 [00:30<00:00, 12.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.3896, Accuracy: 8681/10000 (86.81%)\n",
            "\n",
            "Learning Rate = 0.0001\n",
            "\n",
            "EPOCH: 32\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.5209991931915283 Batch_id=390 Accuracy=82.54: 100%|██████████| 391/391 [00:30<00:00, 12.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.3871, Accuracy: 8696/10000 (86.96%)\n",
            "\n",
            "Learning Rate = 0.0001\n",
            "\n",
            "EPOCH: 33\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.3787476420402527 Batch_id=390 Accuracy=82.50: 100%|██████████| 391/391 [00:31<00:00, 12.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.3882, Accuracy: 8684/10000 (86.84%)\n",
            "\n",
            "Learning Rate = 0.0001\n",
            "\n",
            "EPOCH: 34\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loss=0.5113968253135681 Batch_id=390 Accuracy=82.75: 100%|██████████| 391/391 [00:31<00:00, 12.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.3866, Accuracy: 8689/10000 (86.89%)\n",
            "\n",
            "Learning Rate = 0.0001\n",
            "\n"
          ]
        }
      ]
    }
  ]
}